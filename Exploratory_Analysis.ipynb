{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Raul_Andrial_Interos_Take_Home-Exploratory_Analysis.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"TmWQ_u1vJ7YW"},"source":["**Interos Take Home Assignment-EDA**\n","\n","**Raul Andrial**\n","\n","In this notebook, I implemented a model that classifies articles if they are of the type \"earn\" or not. The data provided to me was from the Reuters-21578, Distribution 1.0 dataset originally found at http://www.research.att.com/~lewis."]},{"cell_type":"code","metadata":{"id":"uYZkDnlOQIwP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637578406384,"user_tz":300,"elapsed":187,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"60fffe85-52ea-41d1-90fc-006ad644aa55"},"source":["# Before running this notebook, please make sure a shortcut has been created\n","# under 'My Drive' for the shared project folder.\n","#\n","# Then, please insert path to shortcut from 'My Drive' below in path_to project.\n","#\n","\n","path_to_project = r'Raul_Andrial_Interos_Take_Home_ML_Apprentice'\n","\n","from google.colab import drive\n","mnt_loc = r'/content/drive'\n","drive.mount(mnt_loc)\n","\n","# This allows relative paths to be set when exporting data or importing\n","# dependencies from gdrive.\n","#\n","\n","import os\n","\n","os.chdir(f'{mnt_loc}/My Drive/{path_to_project}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cIp7qVpekVUV","executionInfo":{"status":"ok","timestamp":1637578407343,"user_tz":300,"elapsed":830,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"35e17279-c240-4afb-a173-21ff29e928a5"},"source":["import pandas as pd\n","import re\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","from nltk.tokenize import RegexpTokenizer\n","import nltk\n","nltk.download('stopwords')\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","import joblib"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","metadata":{"id":"1NmIh6Eor3am"},"source":["# Not installed by default in Google Colab\n","# Used to convert xml text to a python dictionary\n","# https://pypi.org/project/xmltodict/\n","#\n","\n","import Dependencies.xmltodict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MUGlEzyzvONk"},"source":["# From my github account from a prior project\n","# https://github.com/randr000/MyPythonScripts/blob/main/useful_functions.py\n","# Useful function for exploring dataframes\n","\n","def unique_values(series):\n","    \"\"\"Takes a Pandas Series and returns a DataFrame with all unique values and their counts\"\"\"\n","    \n","    return series.value_counts(dropna=False).rename_axis('Unique Values').reset_index(name='Counts')\n","\n","def print_row_count(dframe):\n","    \"\"\"Takes a dataframe and prints out the total number of rows in a formatted string.\"\"\"\n","    \n","    row_count = len(dframe)\n","    print('Current Row Count: {:,}'.format(row_count))\n","    \n","def count_null(series):\n","    \"\"\"Takes a series and counts and prints the number of null and not null values\"\"\"\n","    \n","    print(\"Series name: {}\".format(series.name))\n","    print(\"The number of missing values is {:,}.\".format(series.isnull().sum()))\n","    print(\"The number of not null values is {:,}.\".format(series.notnull().sum()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7l-hN2iMezDQ"},"source":["# Path within gdrive to where data was stored\n","folder_path = f'{path_to_project}/reuters21578'\n","# folder_path = r'/My Drive/test'\n","\n","# Joined mount_loc and folder_path locations\n","data_path = f'{mnt_loc}/My Drive/{folder_path}'\n","\n","# File extension of data to use.\n","# ex. .xml, .sgm, etc.\n","file_ext = '.sgm'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3LJknwlEdSXu","executionInfo":{"status":"ok","timestamp":1637578407514,"user_tz":300,"elapsed":6,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"365508a7-5532-48fa-e8f4-c5b4fa1592ef"},"source":["for file in os.listdir(data_path):\n","  if file.endswith(file_ext):\n","    print(file)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["reut2-000.sgm\n","reut2-001.sgm\n","reut2-002.sgm\n","reut2-004.sgm\n","reut2-003.sgm\n","reut2-005.sgm\n","reut2-006.sgm\n","reut2-007.sgm\n","reut2-009.sgm\n","reut2-008.sgm\n","reut2-010.sgm\n","reut2-011.sgm\n","reut2-012.sgm\n","reut2-013.sgm\n","reut2-015.sgm\n","reut2-014.sgm\n","reut2-016.sgm\n","reut2-017.sgm\n","reut2-018.sgm\n","reut2-019.sgm\n","reut2-020.sgm\n"]}]},{"cell_type":"code","metadata":{"id":"qcTtOwF9j9e3"},"source":["# Looped through all .sgm files in the directory specified.\n","xml_string = ''\n","for file in os.listdir(data_path):\n","  if file.endswith(file_ext):\n","    with open(f'{data_path}/{file}', 'rb') as f:\n","      # Read xml data from current open file and append to xml_string.\n","      xml_append = f.read().decode('utf-8', 'ignore')\n","      xml_string = f'{xml_string}{xml_append}'\n","\n","# Removed control characters and other special characters.\n","# Control characters were causing errors in parsing the xml text.\n","xml_string = re.sub(r'&#\\d{1,2};', '', xml_string)\n","\n","# Removed all 'DOCTYPE' declarations in concatenated string.\n","xml_string = re.sub(r'<!DOCTYPE.*>', '', xml_string)\n","\n","# Add 'lewis' root tags, from dtd file, in order to parse xml as well as original DOCTYPE declaration.\n","xml_string = f'<!DOCTYPE lewis SYSTEM \"lewis.dtd\"><lewis>{xml_string}</lewis>'\n","\n","# Parsed xml string and converted to dictionary.\n","xml_dict = Dependencies.xmltodict.parse(xml_string)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZ96Lz-80Lzu"},"source":["# Dictionary paths to relevant data:\n","#\n","#   xml_dict['lewis']['REUTERS']\n","#     A list containing all the articles.\n","#\n","#   xml_dict['lewis']['REUTERS'][index]['@TOPICS']\n","#     'YES' or 'NO' depending on if the article has at least on topic associated with it.\n","#\n","#   xml_dict['lewis']['REUTERS'][index]['TOPICS']['D']\n","#     This is where the article's topics go. An article can have one, more than one, or no topics.\n","#     If an article has not topics, there are no 'D' tags.\n","#\n","#   xml_dict['lewis']['REUTERS'][index]['TEXT']['BODY']\n","#     Contains the text of the article's body.\n","#\n","\n","# List of all articles\n","articles = xml_dict['lewis']['REUTERS']\n","\n","# Below, a dataframe was created containing the values of the three attributes listed above.\n","#\n","# I used the link below to help me solve a bug I was having with the list comprehensions.\n","#\n","# https://stackoverflow.com/questions/26264359/why-is-this-list-comprehension-giving-me-a-syntax-error\n","# \n","\n","df = pd.DataFrame({\n","    \n","    'has_topic' : [article['@TOPICS'] for article in articles],\n","\n","    # If there were multiple topics, they were joined together as one string using ',' as the delimiter.\n","    'topic': [None if article['TOPICS'] is None else ','.join(article['TOPICS']['D']) \\\n","                if type(article['TOPICS']['D']) is list else article['TOPICS']['D'] for article in articles],\n","              \n","    'article_text' : [article['TEXT']['BODY'] if 'BODY' in article['TEXT'] else None for article in articles]\n","})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DeybKcs9vocF"},"source":["There were 21 files and 1,000 articles per file, so as a sanity check, I made sure the total rows in the dataframe were 21,000."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gOVFYg3H_nT9","executionInfo":{"status":"ok","timestamp":1637578410434,"user_tz":300,"elapsed":52,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"d8179a41-b089-4d78-f2bd-eba25115263d"},"source":["print_row_count(df)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Current Row Count: 21,000\n"]}]},{"cell_type":"markdown","metadata":{"id":"QdA1MheXU8gL"},"source":["Below, one can see at index 7 that has_topic is not always correct so this column was removed. Also, since it is not possible to classify an article if it has no topics or body text, all rows with missing values were removed."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":362},"id":"LS3FT-4ys0VT","executionInfo":{"status":"ok","timestamp":1637578410435,"user_tz":300,"elapsed":41,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"097ab2af-b983-40ff-a4a9-e09226b96f87"},"source":["df.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>has_topic</th>\n","      <th>topic</th>\n","      <th>article_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>YES</td>\n","      <td>cocoa</td>\n","      <td>Showers continued throughout the week in\\nthe ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NO</td>\n","      <td>None</td>\n","      <td>Standard Oil Co and BP North America\\nInc said...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NO</td>\n","      <td>None</td>\n","      <td>Texas Commerce Bancshares Inc's Texas\\nCommerc...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NO</td>\n","      <td>None</td>\n","      <td>BankAmerica Corp is not under\\npressure to act...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>YES</td>\n","      <td>grain,wheat,corn,barley,oat,sorghum</td>\n","      <td>The U.S. Agriculture Department\\nreported the ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>YES</td>\n","      <td>veg-oil,linseed,lin-oil,soy-oil,sun-oil,soybea...</td>\n","      <td>Argentine grain board figures show\\ncrop regis...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NO</td>\n","      <td>None</td>\n","      <td>Red Lion Inns Limited Partnership\\nsaid it fil...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>YES</td>\n","      <td>None</td>\n","      <td>Moody's Investors Service Inc said it\\nlowered...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>YES</td>\n","      <td>earn</td>\n","      <td>Champion Products Inc said its\\nboard of direc...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>YES</td>\n","      <td>acq</td>\n","      <td>Computer Terminal Systems Inc said\\nit has com...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  has_topic  ...                                       article_text\n","0       YES  ...  Showers continued throughout the week in\\nthe ...\n","1        NO  ...  Standard Oil Co and BP North America\\nInc said...\n","2        NO  ...  Texas Commerce Bancshares Inc's Texas\\nCommerc...\n","3        NO  ...  BankAmerica Corp is not under\\npressure to act...\n","4       YES  ...  The U.S. Agriculture Department\\nreported the ...\n","5       YES  ...  Argentine grain board figures show\\ncrop regis...\n","6        NO  ...  Red Lion Inns Limited Partnership\\nsaid it fil...\n","7       YES  ...  Moody's Investors Service Inc said it\\nlowered...\n","8       YES  ...  Champion Products Inc said its\\nboard of direc...\n","9       YES  ...  Computer Terminal Systems Inc said\\nit has com...\n","\n","[10 rows x 3 columns]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"xzS_DL4SxU4H","executionInfo":{"status":"ok","timestamp":1637578410435,"user_tz":300,"elapsed":37,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"63deb6db-13a7-4168-af5e-df247085d91f"},"source":["unique_values(df['has_topic'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unique Values</th>\n","      <th>Counts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>YES</td>\n","      <td>13146</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NO</td>\n","      <td>6811</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BYPASS</td>\n","      <td>1043</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Unique Values  Counts\n","0           YES   13146\n","1            NO    6811\n","2        BYPASS    1043"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gwlTJDI7TMy","executionInfo":{"status":"ok","timestamp":1637578410436,"user_tz":300,"elapsed":35,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"4f45a8e5-8b70-425f-ddaa-8a5142cc2bea"},"source":["count_null(df['topic'])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Series name: topic\n","The number of missing values is 9,962.\n","The number of not null values is 11,038.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JU0EggU80W0p","executionInfo":{"status":"ok","timestamp":1637578410436,"user_tz":300,"elapsed":22,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"e2fdb702-419d-40be-d5de-6c0a14dccef6"},"source":["count_null(df['article_text'])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Series name: article_text\n","The number of missing values is 2,417.\n","The number of not null values is 18,583.\n"]}]},{"cell_type":"code","metadata":{"id":"rLa9zDWj_qhj"},"source":["df = df.drop(columns='has_topic')\n","df = df.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sMWP14qH1ZBD","executionInfo":{"status":"ok","timestamp":1637578410572,"user_tz":300,"elapsed":17,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"670bfffb-7f64-44f6-b0f7-fdddfdc28a71"},"source":["print_row_count(df)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Current Row Count: 10,083\n"]}]},{"cell_type":"markdown","metadata":{"id":"aUCiyzNo1wyX"},"source":["The text in the article_text column contains the newline character \"\\n\" where there was a line break in the original .sgm files. The code below replaced them with one blank space for each."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1D0jfVY1vRm","executionInfo":{"status":"ok","timestamp":1637578410573,"user_tz":300,"elapsed":15,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"f7a6c5fd-dfe5-4338-8e45-8424ab35fee2"},"source":["df['article_text'].head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    Showers continued throughout the week in\\nthe ...\n","4    The U.S. Agriculture Department\\nreported the ...\n","5    Argentine grain board figures show\\ncrop regis...\n","8    Champion Products Inc said its\\nboard of direc...\n","9    Computer Terminal Systems Inc said\\nit has com...\n","Name: article_text, dtype: object"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"6c4ymFGw2ke5"},"source":["df['article_text'] = df['article_text'].str.replace(r'\\n', ' ')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2FHaNiev2U2E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637578410574,"user_tz":300,"elapsed":11,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"89ac824c-92b7-494f-c581-e3a777c21d8c"},"source":["df['article_text'].head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    Showers continued throughout the week in the B...\n","4    The U.S. Agriculture Department reported the f...\n","5    Argentine grain board figures show crop regist...\n","8    Champion Products Inc said its board of direct...\n","9    Computer Terminal Systems Inc said it has comp...\n","Name: article_text, dtype: object"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"hz-gYUHN3UEj"},"source":["Since the challenge is asking to at least classify news articles of type \"earn\", I created a column where 'True' means an article is of the type \"earn\" and 'False' means it is not."]},{"cell_type":"code","metadata":{"id":"5LiZwI5PJQl6"},"source":["df['earn_topic'] = df['topic'].apply(lambda x: True if 'earn' in x else False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sbLi3br73U_z"},"source":["Since it is possible for an article to have multiple topics, I created a column where 'True' means the article has more than one topic and 'False' means it only has one."]},{"cell_type":"code","metadata":{"id":"f1Hhm22N3JGC"},"source":["df['multi_topic'] = df['topic'].apply(lambda x: True if ',' in x else False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":362},"id":"reh2qSXKLBKR","executionInfo":{"status":"ok","timestamp":1637578410743,"user_tz":300,"elapsed":175,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"aab8c0e3-eb04-4410-8fec-a69358a06034"},"source":["df.head(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topic</th>\n","      <th>article_text</th>\n","      <th>earn_topic</th>\n","      <th>multi_topic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cocoa</td>\n","      <td>Showers continued throughout the week in the B...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>grain,wheat,corn,barley,oat,sorghum</td>\n","      <td>The U.S. Agriculture Department reported the f...</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>veg-oil,linseed,lin-oil,soy-oil,sun-oil,soybea...</td>\n","      <td>Argentine grain board figures show crop regist...</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>earn</td>\n","      <td>Champion Products Inc said its board of direct...</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>acq</td>\n","      <td>Computer Terminal Systems Inc said it has comp...</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>earn</td>\n","      <td>Shr 34 cts vs 1.19 dlrs     Net 807,000 vs 2,8...</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>earn,acq</td>\n","      <td>Ohio Mattress Co said its first quarter, endin...</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>earn</td>\n","      <td>Oper shr loss two cts vs profit seven cts     ...</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>earn</td>\n","      <td>Shr one dlr vs 73 cts     Net 12.6 mln vs 15.8...</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>earn</td>\n","      <td>Dean Foods Co expects earnings for the fourth ...</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                topic  ... multi_topic\n","0                                               cocoa  ...       False\n","4                 grain,wheat,corn,barley,oat,sorghum  ...        True\n","5   veg-oil,linseed,lin-oil,soy-oil,sun-oil,soybea...  ...        True\n","8                                                earn  ...       False\n","9                                                 acq  ...       False\n","10                                               earn  ...       False\n","11                                           earn,acq  ...        True\n","12                                               earn  ...       False\n","13                                               earn  ...       False\n","17                                               earn  ...       False\n","\n","[10 rows x 4 columns]"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"e-Sw7RWu900r"},"source":["Some of the articles were about multiple topics where \"earn\" was one of them. They represented less that half of one percent of the total remaining records, so they were removed and were excluded from training and testing."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7amQVG2B71RG","executionInfo":{"status":"ok","timestamp":1637578410744,"user_tz":300,"elapsed":22,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"b41942d1-e691-4e64-dd29-81951bda3781"},"source":["earn_multi = len(df[(df['earn_topic'] == True) & (df['multi_topic'] == True)])\n","pct =  earn_multi / len(df)\n","print(f'The total number of rows where there are multiple topics and \"earn\" is one of them is: {earn_multi}.')\n","print(f'That represents {pct:.2%} of the total current number of records in the dataframe.')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The total number of rows where there are multiple topics and \"earn\" is one of them is: 41.\n","That represents 0.41% of the total current number of records in the dataframe.\n"]}]},{"cell_type":"code","metadata":{"id":"GEaM9psbPdqj"},"source":["# Removed records where 'earn_topic' and 'multi_topic' are both equal to 'True'.\n","df = df[~((df['earn_topic'] == True) & (df['multi_topic'] == True))]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MEAZdfDc9pZ2","executionInfo":{"status":"ok","timestamp":1637578410745,"user_tz":300,"elapsed":18,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"b060e62f-5735-486f-96fd-c6e348d22a11"},"source":["print_row_count(df)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Current Row Count: 10,042\n"]}]},{"cell_type":"markdown","metadata":{"id":"t_CwBies_WgF"},"source":["For the remaining records, about 64% percent of them did not have \"earn\" as a topic and about 36% did. The data was not extremely out of balance so no over or undersampling was conducted."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"iRYztgeC_Vr6","executionInfo":{"status":"ok","timestamp":1637578410745,"user_tz":300,"elapsed":14,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"ad225ae6-2e00-4a29-c554-ee6c0f7abed7"},"source":["unique_values(df['earn_topic'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unique Values</th>\n","      <th>Counts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>False</td>\n","      <td>6457</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>True</td>\n","      <td>3585</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unique Values  Counts\n","0          False    6457\n","1           True    3585"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"-GAsCV3ydHGD"},"source":["Below are the next steps I took to prepare the articles' text for model training. Stemming was chosen over lemmatization since it is simpler and is faster. This decision would have been revisted if model performance was poor."]},{"cell_type":"code","metadata":{"id":"1zLu2_cT5R7E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637578434566,"user_tz":300,"elapsed":23833,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"520a53fc-0141-4b3d-948c-dbb6eb72780a"},"source":["# https://towardsdatascience.com/nlp-for-beginners-cleaning-preprocessing-text-data-ae8e306bef0f\n","#\n","# From my github account from a prior project\n","# https://github.com/randr000/MyPythonJupyterNotebooks/blob/main/Twitter%20Tweepy%20Data%20Cleaning%20for%20Text%20Mining.ipynb\n","#\n","\n","# Created a copy of the article_text column and cleaned the data in the new copy\n","df['cleaned_text'] = df['article_text']\n","\n","# Made every letter lowercase\n","df['cleaned_text'] = df['cleaned_text'].str.lower()\n","\n","# Removed all hyperlinks\n","df['cleaned_text'] = df['cleaned_text'].str.replace(r'(https?:/?/?\\S+)', '', flags=re.IGNORECASE)\n","\n","# Removed any leading and trailing whitespace\n","df['cleaned_text'] = df['cleaned_text'].str.strip()\n","\n","# Removed all punctuation\n","df['cleaned_text'] = df['cleaned_text'].str.replace(r'[^\\w\\s]', '')\n","\n","# Removed any numbers\n","df['cleaned_text'] = df['cleaned_text'].str.replace(r'\\d', '')\n","\n","# Tokenized text\n","tokenizer = RegexpTokenizer(r'\\w+')\n","df['cleaned_text'] = df['cleaned_text'].apply(lambda x: tokenizer.tokenize(x))\n","\n","# Removed stop words\n","def remove_stop_words(text, stop_words):\n","  return [w for w in text if w not in stop_words]\n","\n","stop = stopwords.words('english')\n","df['cleaned_text'] = df['cleaned_text'].apply(remove_stop_words, stop_words=stop)\n","\n","# Stemmed all words\n","ps = PorterStemmer()\n","\n","def stem_words(text):\n","  return [ps.stem(w) for w in text]\n","\n","df['cleaned_text'] = df['cleaned_text'].apply(stem_words)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"isdwkdhiWOCu","executionInfo":{"status":"ok","timestamp":1637578434570,"user_tz":300,"elapsed":44,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"6c4bfb7e-814e-462a-f6d9-b108fd21a6bb"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topic</th>\n","      <th>article_text</th>\n","      <th>earn_topic</th>\n","      <th>multi_topic</th>\n","      <th>cleaned_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cocoa</td>\n","      <td>Showers continued throughout the week in the B...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>[shower, continu, throughout, week, bahia, coc...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>grain,wheat,corn,barley,oat,sorghum</td>\n","      <td>The U.S. Agriculture Department reported the f...</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>[us, agricultur, depart, report, farmerown, re...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>veg-oil,linseed,lin-oil,soy-oil,sun-oil,soybea...</td>\n","      <td>Argentine grain board figures show crop regist...</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>[argentin, grain, board, figur, show, crop, re...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>earn</td>\n","      <td>Champion Products Inc said its board of direct...</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>[champion, product, inc, said, board, director...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>acq</td>\n","      <td>Computer Terminal Systems Inc said it has comp...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>[comput, termin, system, inc, said, complet, s...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               topic  ...                                       cleaned_text\n","0                                              cocoa  ...  [shower, continu, throughout, week, bahia, coc...\n","4                grain,wheat,corn,barley,oat,sorghum  ...  [us, agricultur, depart, report, farmerown, re...\n","5  veg-oil,linseed,lin-oil,soy-oil,sun-oil,soybea...  ...  [argentin, grain, board, figur, show, crop, re...\n","8                                               earn  ...  [champion, product, inc, said, board, director...\n","9                                                acq  ...  [comput, termin, system, inc, said, complet, s...\n","\n","[5 rows x 5 columns]"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"QN7lO_O7ebc_"},"source":["There were other words that were extremely common in both the \"earn\" and \"not earn\" type articles. The code below determined what those words were and removed them from all records."]},{"cell_type":"code","metadata":{"id":"BrYJkf5nE8_e"},"source":["def count_words(lst, count_dict):\n","  \"\"\"Counts words in a list and adds them to dictionary passed as arguement\"\"\"\n","  for word in lst:\n","    if word not in count_dict:\n","      count_dict[word] = 1\n","    else:\n","      count_dict[word] += 1\n","\n","def calc_word_pct(i, total):\n","  \"\"\"Calculates the percentage of the total word count for the current word\"\"\"\n","  return (i / total) * 100\n","\n","earn_df = df[df['earn_topic'] == True]\n","not_earn_df = df[df['earn_topic'] == False]\n","\n","# Dictionaries where a word is the key and its count is the value.\n","earn_word_count = {}\n","not_earn_word_count = {}\n","\n","# Calculated the word counts and populated the dictionaries.\n","earn_df['cleaned_text'].apply(count_words, count_dict=earn_word_count)\n","not_earn_df['cleaned_text'].apply(count_words, count_dict=not_earn_word_count)\n","\n","# Sorted lists of tuples in descending order containing each word and its count.\n","earn_lst = sorted(earn_word_count.items(), key=lambda x: x[1], reverse=True)\n","not_earn_lst = sorted(not_earn_word_count.items(), key=lambda x: x[1], reverse=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"qcu6IK4a3IJb","executionInfo":{"status":"ok","timestamp":1637578434913,"user_tz":300,"elapsed":17,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"a9046e52-71e6-47c7-dbd5-1c9fd4e1bbf6"},"source":["# Created dataframe for the \"earn\" article word counts as well as calculated a word's\n","# overall count percentage.\n","#\n","\n","earn_df_wc = pd.DataFrame(earn_lst, columns=['word', 'earn_count'])\n","earn_df_wc.set_index('word', inplace=True)\n","earn_count_sum = earn_df_wc['earn_count'].sum()\n","earn_df_wc['earn_count_pct'] = earn_df_wc['earn_count'].apply(calc_word_pct, total=earn_count_sum)\n","earn_df_wc.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>earn_count</th>\n","      <th>earn_count_pct</th>\n","    </tr>\n","    <tr>\n","      <th>word</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>vs</th>\n","      <td>13101</td>\n","      <td>7.928084</td>\n","    </tr>\n","    <tr>\n","      <th>mln</th>\n","      <td>10535</td>\n","      <td>6.375266</td>\n","    </tr>\n","    <tr>\n","      <th>ct</th>\n","      <td>7461</td>\n","      <td>4.515032</td>\n","    </tr>\n","    <tr>\n","      <th>dlr</th>\n","      <td>5932</td>\n","      <td>3.589756</td>\n","    </tr>\n","    <tr>\n","      <th>net</th>\n","      <td>4780</td>\n","      <td>2.892622</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      earn_count  earn_count_pct\n","word                            \n","vs         13101        7.928084\n","mln        10535        6.375266\n","ct          7461        4.515032\n","dlr         5932        3.589756\n","net         4780        2.892622"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"PPdIrh4g4yJ4","executionInfo":{"status":"ok","timestamp":1637578434914,"user_tz":300,"elapsed":15,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"e25bca1d-deed-42d5-d061-eea98aa09935"},"source":["# Created dataframe for the \"not earn\" article word counts as well as calculated a word's\n","# overall count percentage.\n","#\n","\n","not_earn_df_wc = pd.DataFrame(not_earn_lst, columns=['word', 'not_earn_count'])\n","not_earn_df_wc.set_index('word', inplace=True)\n","not_earn_count_sum = not_earn_df_wc['not_earn_count'].sum()\n","not_earn_df_wc['not_earn_count_pct'] = not_earn_df_wc['not_earn_count'].apply(calc_word_pct, total=not_earn_count_sum)\n","not_earn_df_wc.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>not_earn_count</th>\n","      <th>not_earn_count_pct</th>\n","    </tr>\n","    <tr>\n","      <th>word</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>said</th>\n","      <td>23378</td>\n","      <td>3.551835</td>\n","    </tr>\n","    <tr>\n","      <th>pct</th>\n","      <td>8373</td>\n","      <td>1.272115</td>\n","    </tr>\n","    <tr>\n","      <th>dlr</th>\n","      <td>7042</td>\n","      <td>1.069896</td>\n","    </tr>\n","    <tr>\n","      <th>mln</th>\n","      <td>6974</td>\n","      <td>1.059564</td>\n","    </tr>\n","    <tr>\n","      <th>reuter</th>\n","      <td>6949</td>\n","      <td>1.055766</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        not_earn_count  not_earn_count_pct\n","word                                      \n","said             23378            3.551835\n","pct               8373            1.272115\n","dlr               7042            1.069896\n","mln               6974            1.059564\n","reuter            6949            1.055766"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"wds_0pJo7WvX"},"source":["# Merged the two word count dataframes created above.\n","word_count_df = pd.concat([earn_df_wc, not_earn_df_wc], axis=1)\n","\n","# Calculated the percentage difference between the \"earn\" and \"not earn\" word counts.\n","# A value of 0 would indicate a word appears in both article type with the same ratio.\n","#\n","word_count_df['pct_diff'] = abs(word_count_df['earn_count_pct'] - word_count_df['not_earn_count_pct'])\n","\n","# Created a list of stemmed stop words to be removed from \"earn\" and \"not earn\" corpuses.\n","my_stemmed_stop_words = word_count_df[word_count_df['pct_diff'] < 1].index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dt_CUm6_AK2W"},"source":["# Exported my_stemmed_stop_words for cleaning future test data.\n","\n","with open('Dependencies/my_stop_words.py', 'w') as f:\n","  f.write('my_stop_words = [\\n')\n","  for w in my_stemmed_stop_words:\n","    f.write(f'\"{w}\",\\n')\n","  f.write(']')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I_Mrd982OHtF"},"source":["# Removed additional stop words\n","df['cleaned_text'] = df['cleaned_text'].apply(remove_stop_words, stop_words=my_stemmed_stop_words)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"hklB4XzAOz9R","executionInfo":{"status":"ok","timestamp":1637578435734,"user_tz":300,"elapsed":17,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"ee80dd1f-754d-46bb-f0a1-798dcd096b5f"},"source":["df[['earn_topic', 'cleaned_text']].head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>earn_topic</th>\n","      <th>cleaned_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>False</td>\n","      <td>[shower, bahia, cocoa, zone, allevi, drought, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>False</td>\n","      <td>[farmerown, fiveday, dlrsbusorghum, cwt, natl,...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>False</td>\n","      <td>[crop, oilse, thousand, bracket, wheat, maiz, ...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>True</td>\n","      <td>[said, said, mln, mln, reuter]</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>False</td>\n","      <td>[said, mln, sedio, lugano, dlr, said, dlr, sai...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   earn_topic                                       cleaned_text\n","0       False  [shower, bahia, cocoa, zone, allevi, drought, ...\n","4       False  [farmerown, fiveday, dlrsbusorghum, cwt, natl,...\n","5       False  [crop, oilse, thousand, bracket, wheat, maiz, ...\n","8        True                     [said, said, mln, mln, reuter]\n","9       False  [said, mln, sedio, lugano, dlr, said, dlr, sai..."]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"jpzv9jhalHJu"},"source":["Below, the text was split into training and test sets. The text was also vectorized in order to be able to use it as input for the model."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"aDo1pirUipxy","executionInfo":{"status":"ok","timestamp":1637578435735,"user_tz":300,"elapsed":16,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"181cd4da-0572-49e1-a275-3049f900f25c"},"source":["# I used some ideas and code from the following links:\n","#\n","# https://datascience.stackexchange.com/questions/24376/use-of-tfidfvectorizer-on-dataframe\n","# https://gtraskas.github.io/post/spamit/\n","# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n","# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n","# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n","# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_predictions\n","# https://towardsdatascience.com/how-to-build-and-apply-naive-bayes-classification-for-spam-filtering-2b8d3308501\n","# https://online.stat.psu.edu/stat507/lesson/10/10.3\n","# https://medium.com/@shrutisaxena0617/precision-vs-recall-386cf9f89488\n","# https://medium.com/@harsz89/persist-reuse-trained-machine-learning-models-using-joblib-or-pickle-in-python-76f7e4fd707\n","#\n","\n","# Created a new dataframe with just the data needed for training and testing.\n","xy_df = df.loc[:, ['earn_topic', 'cleaned_text']]\n","\n","# Joined each list of words under cleaned_text as strings in order to use the data\n","# with the TfidfVectorizer package.\n","#\n","\n","xy_df['cleaned_text'] = [' '.join(words) for words in xy_df['cleaned_text'].values]\n","xy_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>earn_topic</th>\n","      <th>cleaned_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>False</td>\n","      <td>shower bahia cocoa zone allevi drought tempora...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>False</td>\n","      <td>farmerown fiveday dlrsbusorghum cwt natl ratex...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>False</td>\n","      <td>crop oilse thousand bracket wheat maiz oilse s...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>True</td>\n","      <td>said said mln mln reuter</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>False</td>\n","      <td>said mln sedio lugano dlr said dlr said sedio ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   earn_topic                                       cleaned_text\n","0       False  shower bahia cocoa zone allevi drought tempora...\n","4       False  farmerown fiveday dlrsbusorghum cwt natl ratex...\n","5       False  crop oilse thousand bracket wheat maiz oilse s...\n","8        True                           said said mln mln reuter\n","9       False  said mln sedio lugano dlr said dlr said sedio ..."]},"metadata":{},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"Q3DYNCznroXk"},"source":["vectorizer = TfidfVectorizer()\n","\n","# Vectorized all data in cleaned_text.\n","X = vectorizer.fit_transform(xy_df['cleaned_text'])\n","\n","# Set \"earn_topic\" as the target variable.\n","y = xy_df['earn_topic']\n","\n","# Split data into training and test data sets.\n","# 80% training, 20% testing\n","#\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xs1G6H04oCYe"},"source":["I chose to implement a Naive Bayes classifier to create the model due to the fact that it is a simple but effective algorithm in classifying text. It is also very popular in spam filtering applications. While I am not classifying whether or not an article is spam, it is a similar problem."]},{"cell_type":"code","metadata":{"id":"tdBWrztRn79t"},"source":["# Initialized model.\n","clf = MultinomialNB()\n","\n","# Trained model using training data.\n","clf.fit(X_train, y_train)\n","\n","# Made predictions using test data.\n","predictions = clf.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JEa9kIq0rZOA"},"source":["The overall accuracy of the model was about 96.6%."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7O-jKaH0tpU9","executionInfo":{"status":"ok","timestamp":1637578436129,"user_tz":300,"elapsed":28,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"de9fc3ca-0a6b-4157-a1dc-983371999bb0"},"source":["print(f'Total accuracy is {accuracy_score(y_test, predictions):.2%}.')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total accuracy is 96.57%.\n"]}]},{"cell_type":"markdown","metadata":{"id":"RwM43pQbsaRU"},"source":["Both sensitivity and specificity were above 90% and the F1 score was about .95 which indicates the model is good at classifying both types of articles."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":278},"id":"0CCzzNKVwpkJ","executionInfo":{"status":"ok","timestamp":1637578436285,"user_tz":300,"elapsed":169,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"31242b8e-66a5-4c23-b928-04d40d90b556"},"source":["# Created a confusion matrix to visualize specificity and sensitivity.\n","\n","cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n","disp.plot()\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Z1JP-hAxrzx","executionInfo":{"status":"ok","timestamp":1637578436287,"user_tz":300,"elapsed":20,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"32318795-2d4b-4787-e59a-0b0b00ae1d92"},"source":["# Printed confusion matrix value to make sure tn, tp, fn, and fp\n","# variables are correctly initialized.\n","#\n","\n","print(cm)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1269   20]\n"," [  49  671]]\n"]}]},{"cell_type":"code","metadata":{"id":"-SrCD50oyXLO"},"source":["tn, fp = cm[0]\n","fn, tp = cm[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufiyxJPiyzC9","executionInfo":{"status":"ok","timestamp":1637578436289,"user_tz":300,"elapsed":18,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"80778f5a-1235-450e-cf99-897ba95e27f4"},"source":["\n","sensitivity = (tp / (tp + fn)) * 100\n","specificity = (tn / (tn + fp)) * 100\n","\n","print(f'Sensitivity: {sensitivity:.2f}%')\n","print(f'Specificity: {specificity:.2f}%')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sensitivity: 93.19%\n","Specificity: 98.45%\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dT8YK2Vez-Yt","executionInfo":{"status":"ok","timestamp":1637578436290,"user_tz":300,"elapsed":15,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"ca681c9a-fa34-47ae-8e84-b295abc3c138"},"source":["precision = (tp / (tp + fp))\n","recall = sensitivity / 100\n","\n","f1 = 2 *((precision * recall) / (precision + recall))\n","\n","print(f'Precision: {precision:.4f}')\n","print(f'Recall: {recall:.4f}')\n","print(f'F1 Score: {f1:.4f}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.9711\n","Recall: 0.9319\n","F1 Score: 0.9511\n"]}]},{"cell_type":"markdown","metadata":{"id":"I4bIgrw7wkpr"},"source":["Below, I exported both the classifier model as well as the text vectorizer. This allows for both to be loaded in the future without retraining."]},{"cell_type":"code","metadata":{"id":"VWuuOeWe5pLW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637578436561,"user_tz":300,"elapsed":282,"user":{"displayName":"Raul Andrial","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14344410736653675423"}},"outputId":"5d6dace2-678c-4b77-ad11-c2e883e63cfe"},"source":["# Exported Classifier model\n","joblib.dump(clf, 'Dependencies/clf_model.pkl')\n","\n","# Exported vectorizer\n","joblib.dump(vectorizer, 'Dependencies/vectorizer.pkl')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Dependencies/vectorizer.pkl']"]},"metadata":{},"execution_count":44}]}]}